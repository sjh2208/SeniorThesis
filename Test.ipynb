{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013f55c7-1a6d-4393-8eff-d173ff7378e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import special, stats\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-large')\n",
    "\n",
    "sentiment_tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "finetuned_model = GPT2LMHeadModel.from_pretrained('./finetuned_model')\n",
    "finetuned_model.eval()\n",
    "\n",
    "sentiment_model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "sentiment_model.eval()\n",
    "\n",
    "df = pd.read_csv('./test_data.csv').filter(['text', 'label'], axis=1)\n",
    "\n",
    "sent_probs = pd.read_csv('./analysis_results/sentiment_dist.csv')\n",
    "avg_ce_probs = pd.read_csv('./analysis_results/avg_ce_dist.csv')\n",
    "max_ce_probs = pd.read_csv('./analysis_results/max_ce_dist.csv')\n",
    "cond_probs = pd.read_csv('./analysis_results/3d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2cb372-b27f-48d5-9bcf-ff82823f8b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define methods for extracting cross-entropy and sentiment from the models\n",
    "\n",
    "def get_tokenized(prompt):\n",
    "    tokens=tokenizer.encode(prompt)\n",
    "    tokenized = [tokenizer.decode(t) for t in tokens]\n",
    "    return tokenized\n",
    "\n",
    "def get_token_nums(tokens):\n",
    "    nums = [tokenizer.encode(t) for t in tokens]\n",
    "    return nums\n",
    "\n",
    "def get_probs(tokens, model):\n",
    "    \n",
    "    #convert to tensor variable\n",
    "    tokens_tensor = torch.tensor([tokens])\n",
    "    \n",
    "    #get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor)\n",
    "    predictions = outputs[0]\n",
    "    \n",
    "    #compile probability distribution outputs\n",
    "    probs_list = [torch.softmax(predictions[0][i],-1).data.numpy() for i in range(len(predictions[0]))]\n",
    "        \n",
    "    return probs_list\n",
    "\n",
    "def cross_entropy(p, q):\n",
    "    return -np.sum(special.xlogy(p, q))\n",
    "\n",
    "def get_cross_entropy(tokens, probs):\n",
    "    \n",
    "    #q is the predicted distribution, p is the one-hot vector representing the actual next token\n",
    "    #q = probs[i][0], p = np.zeros(len(q)), p[tokens[i + 1]] = 1\n",
    "    \n",
    "    def hot(a, i):\n",
    "        a[tokens[i + 1]] = 1\n",
    "        return a\n",
    "\n",
    "    ces = [cross_entropy(hot(np.zeros(len(probs[i][0])), i), probs[i][0]) for i in range(len(probs) - 1)]\n",
    "    return ces\n",
    "\n",
    "def get_sentiment_scores(text):\n",
    "    \n",
    "    tokens = sentiment_tokenizer.encode(text)[:512]\n",
    "    tokens_tensor = torch.tensor([tokens])\n",
    "    output = special.softmax(sentiment_model(tokens_tensor)[0][0].detach().numpy())\n",
    "    \n",
    "    return output\n",
    "\n",
    "def label(scores):\n",
    "    idx = np.argmax(scores)\n",
    "    if idx == 0:\n",
    "        return 'Negative'\n",
    "    elif idx == 1:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'\n",
    "    \n",
    "def get_results(df):\n",
    "    pd.set_option('display.max_rows', 10)\n",
    "    corr = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for i in range(len(df.index)):\n",
    "        actual = int(df.loc[i, 'label']) \n",
    "        pred = int(df.loc[i, 'predict'])\n",
    "            \n",
    "        if actual == pred:\n",
    "            corr += 1\n",
    "            \n",
    "        if actual == 1:\n",
    "            if pred == 1:\n",
    "                tp += 1\n",
    "            elif pred == 0:\n",
    "                fn += 1\n",
    "        \n",
    "        elif actual == 0:\n",
    "            if pred == 0:\n",
    "                tn += 1\n",
    "            elif pred == 1:\n",
    "                fp += 1\n",
    "                \n",
    "    array = [[tp, fn],\n",
    "             [fp, tn]]\n",
    "\n",
    "    conf = pd.DataFrame(data=array)\n",
    "    conf = conf.rename(columns={0:'Predicted Fake', 1:'Predicted True'})\n",
    "    conf = conf.rename(index={0:'Actual Fake', 1:'Actual True'})\n",
    "    \n",
    "    display(df)\n",
    "    display(conf)\n",
    "    print(f'% correct: {corr/len(df.index)}')\n",
    "    print(f'True Positive Rate: {tp/(tp+fn)}')\n",
    "    print(f'True Negative Rate: {tn/(tn+fp)}')\n",
    "    print(f'False Positive Rate: {fp/(fp+tn)}')\n",
    "    print(f'False Negative Rate: {fn/(fn+tp)}')\n",
    "    \n",
    "def greater(lis, bench):\n",
    "    count = 0\n",
    "    for l in lis:\n",
    "        if l > bench:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def cont_sent(sents):\n",
    "    return (1*sents[0] + 2*sents[1] + 3*sents[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cc6dd4-6e10-4496-8fee-2cee102efb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "how_many = 50\n",
    "sample = df.sample(n=how_many).reset_index()\n",
    "\n",
    "print('Starting processing...')\n",
    "tokenized = [get_tokenized(text)[:1024] for text in sample['text']]\n",
    "tokens = [get_token_nums(token) for token in tokenized]\n",
    "probs = [get_probs(toks, finetuned_model) for toks in tokens]\n",
    "zipped = zip(tokens, probs)\n",
    "ces = [get_cross_entropy(z[0], z[1]) for z in zipped]\n",
    "avg_ces = [np.mean(ce) for ce in ces]\n",
    "\n",
    "sent_scores = [get_sentiment_scores(text) for text in sample['text']]\n",
    "sent_label = [label(scores) for scores in sent_scores]\n",
    "print('Finished processing!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298401ab-2112-4b9b-aadb-f78d69001ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only based on sentiment\n",
    "\n",
    "for i in sample.index:\n",
    "    sentiment = cont_sent(sent_scores[i])\n",
    "    \n",
    "    fake_dist = np.absolute(sent_probs['fake_sent'] - sentiment)\n",
    "    fake_closest = fake_dist.argmin()\n",
    "    fake_prob = sent_probs.loc[fake_closest, 'fake_prob']\n",
    "    \n",
    "    true_dist = np.absolute(sent_probs['true_sent'] - sentiment)\n",
    "    true_closest = true_dist.argmin()\n",
    "    true_prob = sent_probs.loc[true_closest, 'true_prob']\n",
    "    \n",
    "    bayes_true_sent = true_prob * 0.5\n",
    "    bayes_fake_sent = fake_prob * 0.5\n",
    "    \n",
    "    if bayes_true_sent > bayes_fake_sent:\n",
    "        sample.loc[i, 'predict'] = '0'\n",
    "    else:\n",
    "        sample.loc[i, 'predict'] = '1'\n",
    "        \n",
    "print('Prediction based on sentiment:')\n",
    "get_results(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f891abe-1253-4d9b-80bb-af163e436ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only based on avg cross-entropy\n",
    "\n",
    "for i in sample.index:\n",
    "    ce = avg_ces[i]\n",
    "    \n",
    "    fake_dist = np.absolute(avg_ce_probs['fake_ce'] - ce)\n",
    "    fake_closest = fake_dist.argmin()\n",
    "    fake_prob = ce * avg_ce_probs.loc[fake_closest, 'fake_prob']\n",
    "    \n",
    "    true_dist = np.absolute(avg_ce_probs['true_ce'] - ce)\n",
    "    true_closest = true_dist.argmin()\n",
    "    true_prob = ce * avg_ce_probs.loc[true_closest, 'true_prob']\n",
    "    \n",
    "    bayes_true_ce = true_prob * 0.5\n",
    "    bayes_fake_ce = fake_prob * 0.5\n",
    "    \n",
    "    if bayes_true_ce > bayes_fake_ce:\n",
    "        sample.loc[i, 'predict'] = '0'\n",
    "    else:\n",
    "        sample.loc[i, 'predict'] = '1'\n",
    "        \n",
    "print('Prediction based on average cross-entropy:')\n",
    "get_results(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d474694-e78e-4e02-b4b3-6118f5529cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only based on max cross-entropy\n",
    "\n",
    "for i in sample.index:\n",
    "    ce = max(ces[i])\n",
    "    \n",
    "    fake_dist = np.absolute(max_ce_probs['fake_ce'] - ce)\n",
    "    fake_closest = fake_dist.argmin()\n",
    "    fake_prob = ce * max_ce_probs.loc[fake_closest, 'fake_prob']\n",
    "    \n",
    "    true_dist = np.absolute(max_ce_probs['true_ce'] - ce)\n",
    "    true_closest = true_dist.argmin()\n",
    "    true_prob = ce * max_ce_probs.loc[true_closest, 'true_prob']\n",
    "    \n",
    "    bayes_true_ce = true_prob * 0.5\n",
    "    bayes_fake_ce = fake_prob * 0.5\n",
    "    \n",
    "    if bayes_true_ce > bayes_fake_ce:\n",
    "        sample.loc[i, 'predict'] = '0'\n",
    "    else:\n",
    "        sample.loc[i, 'predict'] = '1'\n",
    "        \n",
    "print('Prediction based on maximum cross-entropy:')\n",
    "get_results(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6adc3d-b292-40a6-a586-c8e2b0f73864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with updating now (sentiment, max, average)\n",
    "\n",
    "for i in sample.index:\n",
    "    sentiment =  sentiment = cont_sent(sent_scores[i])\n",
    "    max_ce = max(ces[i])\n",
    "    avg_ce = avg_ces[i]\n",
    "    \n",
    "    t_sent_dist = np.absolute(sent_probs['true_sent'] - sentiment)\n",
    "    t_sent_closest = t_sent_dist.argmin()\n",
    "    t_sent_prob = sent_probs.loc[t_sent_closest, 'true_prob']\n",
    "    f_sent_dist = np.absolute(sent_probs['fake_sent'] - sentiment)\n",
    "    f_sent_closest = f_sent_dist.argmin()\n",
    "    f_sent_prob = sent_probs.loc[f_sent_closest, 'fake_prob']\n",
    "    sent_true = t_sent_prob * 0.5\n",
    "    sent_fake = f_sent_prob * 0.5\n",
    "    #sample.at[i, 'sent_true'] = sent_true\n",
    "    #sample.at[i, 'sent_fake'] = sent_fake\n",
    "    \n",
    "    t_max_dist = np.absolute(max_ce_probs['true_ce'] - max_ce)\n",
    "    t_max_closest = t_max_dist.argmin()\n",
    "    t_max_prob = max_ce_probs.loc[t_max_closest, 'true_prob']\n",
    "    f_max_dist = np.absolute(max_ce_probs['fake_ce'] - max_ce)\n",
    "    f_max_closest = f_max_dist.argmin()\n",
    "    f_max_prob = max_ce_probs.loc[f_max_closest, 'fake_prob']\n",
    "    max_true = t_max_prob * sent_true\n",
    "    max_fake = f_max_prob * sent_fake\n",
    "    #sample.at[i, 'max_true'] = max_true\n",
    "    #sample.at[i, 'max_fake'] = max_fake\n",
    "    \n",
    "    t_avg_dist = np.absolute(avg_ce_probs['true_ce'] - avg_ce)\n",
    "    t_avg_closest = t_avg_dist.argmin()\n",
    "    t_avg_prob = avg_ce_probs.loc[t_avg_closest, 'true_prob']\n",
    "    f_avg_dist = np.absolute(avg_ce_probs['fake_ce'] - avg_ce)\n",
    "    f_avg_closest = f_avg_dist.argmin()\n",
    "    f_avg_prob = avg_ce_probs.loc[f_avg_closest, 'fake_prob']\n",
    "    avg_true = t_avg_prob * max_true\n",
    "    avg_fake = f_avg_prob * max_fake\n",
    "    #sample.at[i, 'avg_true'] = avg_true\n",
    "    #sample.at[i, 'avg_fake'] = avg_fake\n",
    "    \n",
    "    if avg_true > avg_fake:\n",
    "        sample.loc[i, 'predict'] = '0'\n",
    "    else:\n",
    "        sample.loc[i, 'predict'] = '1'\n",
    "        \n",
    "print('Prediction based on all criteria:')\n",
    "get_results(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02821b8c-6ee1-4f74-9120-df7c2e65c8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using two conditions p(T|S,E)\n",
    "\n",
    "for i in sample.index:\n",
    "    sentiment = cont_sent(sent_scores[i])\n",
    "    avg_ce = avg_ces[i]\n",
    "    \n",
    "    closest = np.absolute(cond_probs['s'] - sentiment) + np.absolute(cond_probs['ce'] - avg_ce)\n",
    "    idx = closest.argmin()\n",
    "    \n",
    "    pt = cond_probs.loc[idx, 'pt'] * 0.5\n",
    "    pf = cond_probs.loc[idx, 'pf'] * 0.5\n",
    "    \n",
    "    if pt > pf:\n",
    "        sample.loc[i, 'predict'] = '0'\n",
    "    else:\n",
    "        sample.loc[i, 'predict'] = '1'\n",
    "        \n",
    "print('Prediction based on conditional criteria:')\n",
    "get_results(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aebc4e-e04c-4cd0-b05b-728883671ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
